âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/customer-support-rag.git
cd customer-support-rag

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Add API Key

Create a .env file:

OPENAI_API_KEY=your_api_key_here

ğŸ“¦ requirements.txt
openai
faiss-cpu
langchain
python-dotenv
tiktoken
pypdf

ğŸ§¾ Sample Knowledge Base File

ğŸ“ data/raw_docs/refund-policy.md

Refund Policy

Customers are eligible for a refund within 30 days of purchase.
Refunds are processed within 5â€“7 business days.

ğŸ”„ Document Embedding

ğŸ“ embeddings/embed_docs.py

import os
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

DATA_PATH = "data/raw_docs"
VECTOR_DB_PATH = "embeddings/vector_store"

def load_documents():
    docs = []
    for file in os.listdir(DATA_PATH):
        if file.endswith(".md") or file.endswith(".txt"):
            loader = TextLoader(os.path.join(DATA_PATH, file))
            docs.extend(loader.load())
    return docs

def main():
    documents = load_documents()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100
    )
    chunks = splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings()
    vector_db = FAISS.from_documents(chunks, embeddings)
    vector_db.save_local(VECTOR_DB_PATH)

    print("âœ… Documents embedded successfully")

if __name__ == "__main__":
    main()

ğŸ” Document Retrieval

ğŸ“ retriever/search.py

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS

VECTOR_DB_PATH = "embeddings/vector_store"

def retrieve_docs(query, k=3):
    embeddings = OpenAIEmbeddings()
    vector_db = FAISS.load_local(VECTOR_DB_PATH, embeddings)
    return vector_db.similarity_search(query, k=k)

âœ¨ Answer Generation

ğŸ“ generator/answer_generator.py

from langchain.chat_models import ChatOpenAI
from retriever.search import retrieve_docs

def generate_answer(query):
    docs = retrieve_docs(query)
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""
You are a customer support assistant.
Answer using ONLY the context below.

Context:
{context}

Question:
{query}

Answer:
"""

    llm = ChatOpenAI(temperature=0)
    return llm.predict(prompt)

ğŸ¤– Chatbot Application

ğŸ“ app/chatbot.py

from generator.answer_generator import generate_answer

def main():
    print("ğŸ¤– Customer Support RAG Chatbot")
    print("Type 'exit' to quit\n")

    while True:
        query = input("You: ")
        if query.lower() == "exit":
            break
        response = generate_answer(query)
        print(f"\nBot: {response}\n")

if __name__ == "__main__":
    main()

â–¶ï¸ Run the Project
# Step 1: Embed documents
python embeddings/embed_docs.py

# Step 2: Start chatbot
python app/chatbot.py

ğŸ§ª Example Output
You: What is the refund policy?
Bot: Customers are eligible for a refund within 30 days of purchase.
